{"id":27661,"date":"2021-09-14T22:54:37","date_gmt":"2021-09-15T05:54:37","guid":{"rendered":"https:\/\/coertvonk.com\/?p=27661"},"modified":"2022-04-10T15:49:55","modified_gmt":"2022-04-10T22:49:55","slug":"matrices","status":"publish","type":"post","link":"http:\/\/coertvonk.com\/math\/multivariable-calculus\/linear-algebra\/matrices-27661","title":{"rendered":"Matrices"},"content":{"rendered":"\\(\\)<p>\r\n    <div class=\"postit\">\r\n        <div class=\"note yellow\">\r\n            My notes of the excellent lectures of &#8220;Denis Auroux. 18.02 Multivariable Calculus. Fall 2007. Massachusetts Institute of Technology: MIT OpenCourseWare, <a href=\"https:\/\/ocw.mit.edu\/courses\/18-02-multivariable-calculus-fall-2007\/\">https:\/\/ocw.mit.edu<\/a>. License: <a href=\"https:\/\/creativecommons.org\/licenses\/by-nc-sa\/4.0\/\">Creative Commons BY-NC-SA<\/a>.&#8221;\r\n        <\/div>\r\n    <\/div>\r\n<\/p>\r\n<p>\r\n    Matrices can be used to express linear relations between variables. For example when we change coordinate systems\r\n    from eg. \\((x_1,x_2,x_3)\\) to \\((u_1,u_2,u_3)\\) where\r\n    $$\r\n        \\left\\{\r\n            \\begin{align}\r\n                u_1 &#038;= 2x_1+3x_2+3x_3 \\nonumber \\\\\r\n                u_2 &#038;= 2x_1+4x_2+5x_3 \\nonumber \\\\\r\n                u_3 &#038;= x_1+x_2+2x_3 \\nonumber\r\n            \\end{align}\r\n        \\right.\r\n        \\label{eq:linear}\r\n    $$\r\n<\/p>\r\n<p>\r\n    Expressed as matrix product\r\n    $$\r\n        \\begin{align*}\r\n            \\underbrace{\r\n                \\left[\r\n                    \\begin{matrix}\r\n                        2 &#038; 3 &#038; 3 \\\\\r\n                        2 &#038; 4 &#038; 5 \\\\\r\n                        1 &#038; 1 &#038; 2\r\n                    \\end{matrix}\r\n                \\right]\r\n            }_{A}\\;\r\n            \\underbrace{\r\n                \\left[\r\n                    \\begin{matrix}\r\n                        x_1 \\\\\r\n                        x_2 \\\\\r\n                        x_3\r\n                    \\end{matrix}\r\n                \\right]\r\n            }_{X} &#038;=\r\n            \\underbrace{\r\n                \\left[\r\n                    \\begin{matrix}\r\n                        u_1 \\\\\r\n                        u_2 \\\\\r\n                        u_3\r\n                    \\end{matrix}\r\n                \\right]\r\n            }_{U} \\\r\n            A X &#038;= U\r\n        \\end{align*}\r\n    $$\r\n    Here \\(A\\) is a \\(3\\times 3\\) matrix, and \\(X\\) is a vector or a \\(3\\times 1\\) matrix.\r\n<\/p>\r\n<h2>Matrix Multiplication<\/h2>\r\n<p>\r\n    <strong>Definition:<\/strong>\r\n    <blockquote>\r\n        The entries in \\(A X\\) are the dot-product between the rows in \\(A\\) and the columns in \\(X\\), as shown below\r\n        <div class=\"align-center\">\r\n            <figure>\r\n                <a href=\"https:\/\/coertvonk.com\/wp-content\/uploads\/matrix-multiplication-copy.svg\"><img\r\n                        src=\"https:\/\/coertvonk.com\/wp-content\/uploads\/matrix-multiplication-copy.svg\" alt=\"\" width=\"210\"\r\n                        class=\"alignnone size-medium wp-image-27664\" \/><\/a>\r\n                <figcaption>matrix multiplication<\/figcaption>\r\n            <\/figure>\r\n        <\/div>\r\n    <\/blockquote>\r\n<\/p>\r\n<p>\r\n    For example, the entries of \\(AB\\) are\r\n    $$\r\n        \\left[\r\n            \\begin{matrix}\r\n                1 &#038; 2 &#038; 3 &#038; 4 \\\\\r\n                \\cdot &#038; \\cdot &#038; \\cdot &#038; \\cdot \\\\\r\n                \\cdot &#038; \\cdot &#038; \\cdot &#038; \\cdot \\\\\r\n                \\cdot &#038; \\cdot &#038; \\cdot &#038; \\cdot \\\\\r\n                \\cdot &#038; \\cdot &#038; \\cdot &#038; \\cdot\r\n            \\end{matrix}\r\n        \\right]\\;\r\n        \\left[\r\n            \\begin{matrix}\r\n                0 &#038; \\cdot \\\\\r\n                3 &#038; \\cdot \\\\\r\n                0 &#038; \\cdot \\\\\r\n                2 &#038; \\cdot\r\n            \\end{matrix}\r\n        \\right] =\r\n        \\left[\r\n            \\begin{matrix}\r\n                14 &#038; \\cdot \\\\\r\n                \\cdot &#038; \\cdot \\\\\r\n                \\cdot &#038; \\cdot\r\n            \\end{matrix}\r\n        \\right]\r\n    $$\r\n<\/p>\r\n<p>\r\n    Properties:\r\n    <ul>\r\n        <li><b>The width of \\(A\\) must equal the height of \\(B\\).<\/b><\/li>\r\n        <li>The product \\(AB\\) has the same height as \\(A\\) and the same width as \\(B\\).<\/li>\r\n        <li>Product \\(AB\\) represents: do transformation \\(B\\), <em>then<\/em> transformation \\(A\\). Unfortunately, you\r\n            multiply from right to left. Similar to \\(f(g(x))\\), where you first apply \\(g\\) and then \\(f\\). The product\r\n            \\(BA\\) is not even be defined when the width of \\(B\\) is not equal to the height of \\(A\\). In other words\r\n            \\(AB\\ne BA\\)<\/li>\r\n        <li>They are well behaved associative products: \\((AB)X =A(BX)\\)<\/li>\r\n        <li>\\(BX\\) means we apply transformation \\(B\\) to \\(X\\).\r\n    <\/ul>\r\n<\/p>\r\n<h2>Identity matrix<\/h2>\r\n<p>\r\n    <strong>Definition:<\/strong>\r\n    <blockquote>\r\n        The identify matrix is a matrix that does no transformation: \\(IX=X\\)\r\n    <\/blockquote>\r\n<\/p>\r\n<p>\r\n    The height of \\(I\\) needs to match the width of \\(X\\). \\(I\\) has \\(1\\)&#8217;s on the diagonal, and \\(0\\)&#8217;s everywhere\r\n    else.\r\n    $$\r\n        I_{n\\times n} =\r\n        \\left[\r\n                \\begin{matrix}\r\n                1 &#038; &#038; &#038; \\ldots &#038; 0 \\\\\r\n                &#038; 1 &#038; &#038; &#038; \\vdots \\\\\r\n                &#038; &#038; 1 &#038; &#038; \\\\\r\n                \\vdots &#038; &#038; &#038; \\ddots &#038; \\\\\r\n                0 &#038; \\ldots &#038; &#038; &#038; 1\r\n            \\end{matrix}\r\n        \\right]\r\n        \\nonumber\r\n    $$\r\n<\/p>\r\n<p>\r\n    For example:\r\n    $$\r\n        I_{3\\times3} = \r\n        \\left[\r\n            \\begin{matrix}\r\n                1 &#038; 0 &#038; 0 \\\\\r\n                0 &#038; 1 &#038; 0 \\\\\r\n                0 &#038; 0 &#038; 1\r\n            \\end{matrix}\r\n        \\right]\r\n        \\nonumber\r\n    $$\r\n<\/p>\r\n<h3>Rotation<\/h3>\r\n<p>\r\n    Matrix \\(R\\), gives a \\(\\frac{\\pi}{2}\\) rotation.\r\n    $$\r\n        R = \r\n        \\left[\r\n            \\begin{matrix}\r\n                0 &#038; -1 \\\\\r\n                1 &#038; 0\r\n            \\end{matrix}\r\n        \\right]\r\n        \\nonumber\r\n    $$\r\n<\/p>\r\n<p>\r\n    In general\r\n    $$\r\n        R\r\n        \\left[\r\n            \\begin{matrix}\r\n                x \\\\\r\n                y\r\n            \\end{matrix}\r\n        \\right] =\r\n        \\left[\r\n            \\begin{array}{r}\r\n            -y \\\\\r\n            x\r\n            \\end{array}\r\n        \\right]\r\n        \\nonumber\r\n    $$\r\n<\/p>\r\n<p>\r\n    Try multiplying with unity vector \\(\\hat\\imath\\), \\(\\hat\\jmath\\), or take \\(R\\) squared\r\n    $$\r\n        \\begin{align*}\r\n            R\\; \\hat\\imath &#038;=\r\n            \\left[\r\n                \\begin{array}{rr}\r\n                    0 &#038; -1 \\\\\r\n                    1 &#038; 0\r\n                \\end{array}\r\n            \\right]\r\n            \\left[\r\n                \\begin{matrix}\r\n                    1 \\\\\r\n                    0\r\n                \\end{matrix}\r\n            \\right] =\r\n            \\left[\r\n                \\begin{matrix}\r\n                    0 \\\\\r\n                    1\r\n                \\end{matrix}\r\n            \\right] = \\hat\\jmath \\\\\r\n            R\\;\\hat\\jmath &#038;=\r\n            \\left[\r\n                \\begin{array}{rr}\r\n                    0 &#038; -1 \\\\\r\n                    1 &#038; 0\r\n                \\end{array}\r\n            \\right]\r\n            \\left[\r\n                \\begin{matrix}\r\n                    0 \\\\\r\n                    1\r\n                \\end{matrix}\r\n            \\right] =\r\n            \\left[\r\n                \\begin{array}{r}\r\n                    -1 \\\\\r\n                    0\r\n                \\end{array}\r\n            \\right] = -\\hat\\imath \\\\\r\n            R^2 &#038;=\r\n            \\left[\r\n                \\begin{array}{rr}\r\n                    0 &#038; -1 \\\\\r\n                    1 &#038; 0\r\n                \\end{array}\r\n            \\right]\r\n            \\left[\r\n                \\begin{array}{rr}\r\n                    0 &#038; -1 \\\\\r\n                    1 &#038; 0\r\n                \\end{array}\r\n            \\right] =\r\n            \\left[\r\n                \\begin{array}{rr}\r\n                    -1 &#038; 0 \\\\\r\n                    0 &#038; -1\r\n                \\end{array}\r\n            \\right] =\r\n            -I_{2\\times 2}\r\n        \\end{align*}\r\n        \\nonumber\r\n    $$\r\n<\/p>\r\n<h2 id=\"inverse\">Inverse Matrix<\/h2>\r\n<p>\r\n    <strong>Definition:<\/strong>\r\n    <blockquote>The inverse of matrix \\(A\\) is \\(A^{-1}\\) such that\r\n        $$\r\n            \\shaded{\r\n                \\left\\{\r\n                    \\begin{align*}\r\n                        A\\;A^{-1} &#038;= I \\\\\r\n                        A^{-1}\\;A &#038;= I\r\n                    \\end{align*}\r\n                \\right.\r\n            }\r\n            \\nonumber\r\n        $$\r\n    <\/blockquote>\r\n    That implies that \\(A\\) must be a square matrix (\\(n \\times n\\)).\r\n<\/p>\r\n<p>\r\n    Referring to the system of equations \\(\\eqref{eq:linear}\\), to express variables \\(u_i\\) in terms of \\(x_i\\) values,\r\n    we need to inverse the transformation. For instance: in \\(AX=B\\); let matrix \\(A\\) and \\(B\\) be known what is \\(X\\)?\r\n    $$\r\n        \\begin{align*}\r\n            AX &#038;= B \\Rightarrow \\\\\r\n            A^{-1}(AX) &#038;= A^{-1} B \\Rightarrow \\\\\r\n            IX &#038;= A^{-1} B \\Rightarrow \\\\\r\n            X &#038;= A^{-1} B\r\n        \\end{align*}\r\n    $$\r\n<\/p>\r\n<h3>Method<\/h3>\r\n<p>\r\n    The inverse matrix is calculated using the adjoined matrix\r\n    <blockquote>\r\n        $$\r\n            A^{-1}=\\frac{1}{\\mathrm{det}(A)}\\;\\mathrm{adj}(A)\r\n            \\nonumber\r\n        $$\r\n    <\/blockquote>\r\n<\/p>\r\n<p>\r\n    For this \\(3\\times 3\\) example\r\n    $$\r\n        A=\\left[\r\n            \\begin{matrix}\r\n                2 &#038; 3 &#038; 3 \\\\\r\n                2 &#038; 4 &#038; 5 \\\\\r\n                1 &#038; 1 &#038; 2\r\n            \\end{matrix}\r\n        \\right]\r\n    $$\r\n<\/p>\r\n<p>\r\n    First, find the determinant of \\(A\\)\r\n    $$\r\n        \\det(A)=\r\n        \\left|\r\n            \\begin{array}{rrr}\r\n                2 &#038; 3 &#038; 3 \\\\\r\n                2 &#038; 4 &#038; 5 \\\\\r\n                1 &#038; 1 &#038; 2\r\n            \\end{array}\r\n        \\right| = 3\r\n        \\nonumber\r\n    $$\r\n<\/p>\r\n<p>\r\n    Second, find the minors (matrix of determinants) of matrix \\(A\\)\r\n    $$\r\n        \\mathrm{minors} =\r\n        \\left[\\begin{array}{rrr}\r\n            \\left|\\begin{array}{rrr} 4 &#038; 5 \\\\ 1 &#038; 2 \\end{array}\\right| &#038;\r\n            \\left|\\begin{array}{rrr} 2 &#038; 5 \\\\ 1 &#038; 2 \\end{array}\\right| &#038;\r\n            \\left|\\begin{array}{rrr} 2 &#038; 4 \\\\ 1 &#038; 1 \\end{array}\\right| \\\\\r\n            \\left|\\begin{array}{rrr} 3 &#038; 3 \\\\ 1 &#038; 2 \\end{array}\\right| &#038;\r\n            \\left|\\begin{array}{rrr} 2 &#038; 3 \\\\ 1 &#038; 2 \\end{array}\\right| &#038;\r\n            \\left|\\begin{array}{rrr} 2 &#038; 3 \\\\ 1 &#038; 1 \\end{array}\\right| \\\\\r\n            \\left|\\begin{array}{rrr} 3 &#038; 3 \\\\ 4 &#038; 5 \\end{array}\\right| &#038;\r\n            \\left|\\begin{array}{rrr} 2 &#038; 3 \\\\ 2 &#038; 5 \\end{array}\\right| &#038;\r\n            \\left|\\begin{array}{rrr} 2 &#038; 3 \\\\ 2 &#038; 4 \\end{array}\\right|\r\n        \\end{array}\\right]\r\n        =\r\n        \\left[\\begin{array}{rrr}\r\n            3 &#038; -1 &#038; -2 \\\\\r\n            3 &#038; 1 &#038; -1 \\\\\r\n            3 &#038; 4 &#038; 2\r\n        \\end{array}\\right]\r\n        \\nonumber\r\n    $$\r\n<\/p>\r\n<p>\r\n    Third, find the cofactors. Flip the signs checker board\r\n    $$\r\n        \\begin{array}{rrr}\r\n            + &#038; &#8211; &#038; + \\\\\r\n            &#8211; &#038; + &#038; &#8211; \\\\\r\n            + &#038; &#8211; &#038; +\r\n        \\end{array}\r\n        \\nonumber\r\n    $$\r\n    A &#8216;\\(+\\)&#8217; means leave it alone. A &#8216;\\(-\\)&#8217; means flip the sign. Apply the cofactors to the minors.\r\n    $$\r\n        \\left[\\begin{array}{rrr}\r\n            3 &#038; 1 &#038; -2 \\\\\r\n            -3 &#038; 1 &#038; 1 \\\\\r\n            3 &#038; -4 &#038; 2\r\n        \\end{array}\\right]\r\n        \\nonumber\r\n    $$\r\n<\/p>\r\n<p>\r\n    Fourth, transpose (switch rows and columns) to find the adjoined matrix \\(\\mathrm{adj}(A)\\).\r\n    $$\r\n        \\mathrm{adj}(A) = \r\n        \\left[\\begin{array}{rrr}\r\n            3 &#038; -3 &#038; 3 \\\\\r\n            1 &#038; 1 &#038; -4 \\\\\r\n            -2 &#038; 1 &#038; 2\r\n        \\end{array}\\right]\r\n        \\nonumber\r\n    $$\r\n<\/p>\r\n<p>\r\n    The inverse matrix \\(A^{-1}\\) follows as\r\n    $$\r\n        A^{-1} = \\frac{1}{\\det(A)}\\;\\mathrm{adj}(A) =\r\n        \\frac{1}{3}\r\n        \\left[\\begin{array}{rrr}\r\n            3 &#038; -3 &#038; 3 \\\\\r\n            1 &#038; 1 &#038; -4 \\\\\r\n            -2 &#038; 1 &#038; 2\r\n        \\end{array}\\right]\r\n        \\nonumber\r\n    $$\r\n<\/p>\r\n<h2 id=\"planeequations\">Equations of planes<\/h2>\r\n<p>\r\n    An equation of the form \\(ax+by+cz=d\\), expresses the condition for the point \\((x,y,z)\\) to be in the plane. It\r\n    defines a plane.\r\n<\/p>\r\n<h3>Examples<\/h3>\r\n<h4 id=\"planeequations1\">Plane through the origin<\/h4>\r\n<p>\r\n    Find the equation of the plane through the origin with normal vector \\(\\vec N = \\left\\langle 1, 5, 10\r\n    \\right\\rangle\\).\r\n    <div class=\"align-center\">\r\n        <figure>\r\n            <a href=\"https:\/\/coertvonk.com\/wp-content\/uploads\/plane-with-normal-vector-copy.svg\"><img\r\n                    src=\"https:\/\/coertvonk.com\/wp-content\/uploads\/plane-with-normal-vector-copy.svg\" alt=\"\" width=\"210\"\r\n                    class=\"alignnone size-medium wp-image-27679\" \/><\/a>\r\n            <figcaption>Plane with normal vector<\/figcaption>\r\n        <\/figure>\r\n    <\/div>\r\n<\/p>\r\n<p>\r\n    Point \\(P=(x,y,z)\\) is in the plane when \\(\\vec{OP}\\perp\\vec{N}\\). Therefore, their dot-product must equal zero (see\r\n    <a href=\"\/math\/multivariable-calculus\/linear-algebra\/vectors-27609#planefrompoints2\">vectors<\/a>).\r\n    $$\r\n    \\begin{align*}\r\n        \\overrightarrow{OP}\\cdot\\vec{N} = 0 \\\\\r\n        \\Leftrightarrow\r\n        \\left\\langle x, y, z \\right\\rangle \\cdot\r\n        \\left\\langle 1, 5, 10 \\right\\rangle = 0 \\\\\r\n        \\Leftrightarrow x + 5y + 10z = 0\r\n    \\end{align*}\r\n    $$\r\n<\/p>\r\n<h4 id=\"planeequations2\">Plane not through the origin<\/h4>\r\n<p>\r\n    Find the equation of the plane through \\(P_0=(2,1,-1)\\) with normal vector \\(\\vec N = \\left\\langle 1, 5, 10\r\n    \\right\\rangle\\).\r\n<\/p>\r\n<p>\r\n    The normal vector is the same as in the <a href=\"#planeequations1\">first example<\/a>, therefore it will be the same\r\n    plane, but shifted so that it passes through \\(P_0\\).\r\n    <div class=\"align-center\">\r\n        <figure>\r\n            <a href=\"https:\/\/coertvonk.com\/wp-content\/uploads\/shifted-plane-with-normal-vector-copy.svg\"><img\r\n                    src=\"https:\/\/coertvonk.com\/wp-content\/uploads\/shifted-plane-with-normal-vector-copy.svg\" alt=\"\" width=\"210\"\r\n                    class=\"alignnone size-medium wp-image-27680\" \/><\/a>\r\n            <figcaption>Shifted plane with normal vector<\/figcaption>\r\n        <\/figure>\r\n    <\/div>\r\n<\/p>\r\n<p>\r\n    Point \\(P=(x,y,z)\\) is in the plane when \\(\\overrightarrow{P_0P}\\perp\\overrightarrow{N}\\). Therefore, their\r\n    dot-product must equal zero (see <a href=\"\/math\/multivariable-calculus\/linear-algebra\/vectors-27609#planefrompoints2\">vectors<\/a>). This vector\r\n    \\(\\overrightarrow{P_0P}\\) equals \\(P-P_0\\).\r\n    $$\r\n        \\begin{align*}\r\n            \\left\\langle x-2, y-1, z+1 \\right\\rangle \\cdot\r\n            \\left\\langle 1, 5, 10 \\right\\rangle &#038;= 0 \\\\\r\n            \\Leftrightarrow (x-2)+5(y-1)+10(z+1) &#038;= 0 \\\\\r\n            \\Leftrightarrow \\underline{1}x+\\underline{5}y+\\underline{10}z &#038;= -3\r\n        \\end{align*}\r\n    $$\r\n<\/p>\r\n<p>\r\n    In the equation \\(ax+by+cz=d\\), the coefficients \\(\\left\\langle a,b,c\\right\\rangle\\) is the normal vector\r\n    \\(\\vec{N}\\). Constant \\(d\\) indicates how far the plane is from the origin.\r\n<\/p>\r\n<h5 id=\"planeequations2a\">How could we have found the \\(-3\\) more quickly?<\/h5>\r\n<p>\r\n    The first part of the equation is based on the normal vector\r\n    $$\r\n        x + 5y + 10z = d\r\n        \\label{eq:planeequations2a}\r\n    $$\r\n<\/p>\r\n<p>\r\n    We know \\(P_0\\) is in the plane. Substituting \\(\\left\\langle x,y,z\\right\\rangle=P_0\\) in\r\n    \\(\\eqref{eq:planeequations2a}\\)\r\n    $$\r\n        \\begin{align*}\r\n            1(2)+5(1)+10(-1) &#038;= d \\\\\r\n            \\Leftrightarrow\r\n            d &#038;= -3\r\n        \\end{align*}\r\n        \\nonumber\r\n    $$\r\n<\/p>\r\n<h4 id=\"planeequations3\">Parallel or perpendicular?<\/h4>\r\n<p>\r\n    Are vector \\(\\vec{v}=\\left\\langle 1,2,-1 \\right\\rangle\\) and plane \\(x+y+3z=5\\) parallel, perpendicular or neither?\r\n<\/p>\r\n<p>\r\n    Vector \\(\\vec{v}\\) is perpendicular to the plane when \\(\\vec{v}\\)=\\(s\\;\\vec{N}\\), where \\(s\\) is a scalar. The\r\n    normal vector follows from the coefficients of the plane equation\r\n    $$\r\n        \\vec{N} = \\left\\langle 1,1,3 \\right\\rangle\r\n        \\nonumber\r\n    $$\r\n    Therefore \\(\\vec{V}\\) is not perpendicular to the plane.\r\n<\/p>\r\n<p>\r\n    If \\(\\vec{v}\\) is perpendicular to \\(\\vec{N}\\), it is parallel to the plane. \\(\\vec{v}\\perp\\vec{N}\\) when the\r\n    dot-product equals zero.\r\n    (see <a href=\"\/math\/multivariable-calculus\/linear-algebra\/vectors-27609#planefrompoints2\">vectors<\/a>)\r\n    $$\r\n        \\begin{align*}\r\n            \\vec{v}\\cdot\\vec{N} &#038;=\r\n            \\left\\langle 2, 1, -1 \\right\\rangle \\cdot\r\n            \\left\\langle 1, 1, 3 \\right\\rangle \\\\\r\n            &#038;= 1+2-3 = 0\r\n        \\end{align*}\r\n    $$\r\n    Therefore, \\(\\vec{v}\\) is parallel to the plane.\r\n<\/p>\r\n<h2>Solving systems of equations<\/h2>\r\n<p>\r\n    To solve a system of equations, you try to find a point that is on several planes at the same time.\r\n<\/p>\r\n<h3>Example<\/h3>\r\n<p>\r\n    Find the \\(x,y,z\\) that satisfies the conditions of the \\(3\\times 3\\) linear system:\r\n    $$\r\n        \\left\\{\r\n            \\begin{align*}\r\n                x+ z = 1 \\\\\r\n                x + y = 2 \\\\\r\n                x + 2y + 3z = 3\r\n            \\end{align*}\r\n        \\right.\r\n    $$\r\n<\/p>\r\n<p>\r\n    The first 2 equations represent two planes that intersect in line \\(P_1\\cap P_2\\). The third plane intersects that\r\n    line at the point \\(P(x,y,z)\\), the solution to the linear system.\r\n    <div class=\"align-center\">\r\n        <figure>\r\n            <a href=\"https:\/\/coertvonk.com\/wp-content\/uploads\/3-planes-intersecting-one-solution-copy-1.svg\"><img\r\n                    src=\"https:\/\/coertvonk.com\/wp-content\/uploads\/3-planes-intersecting-one-solution-copy-1.svg\" alt=\"\" width=\"240\"\r\n                    class=\"alignnone size-medium wp-image-27735\" \/><\/a>\r\n            <figcaption>3 planes &#8211; one solution<\/figcaption>\r\n        <\/figure>\r\n    <\/div>\r\n<\/p>\r\n<p>\r\n    Unless:\r\n    <ul>\r\n        <li>\r\n            if the line \\(P_1\\cap P_2\\) is contained in \\(P_3\\), there are infinite many solutions. (Any point on the\r\n            line is a solution.)\r\n        <\/li>\r\n        <li>\r\n            if the line \\(P_1\\cap P_2\\) is parallel to \\(P_3\\), then there are no solutions.\r\n        <\/li>\r\n    <\/ul>\r\n<\/p>\r\n<p>\r\n    <div class=\"align-center\">\r\n        <figure style=\"display: inline-block;\">\r\n            <a href=\"https:\/\/coertvonk.com\/wp-content\/uploads\/3-planes-intersecting-infinite-solutions-copy.svg\"><img\r\n                    src=\"https:\/\/coertvonk.com\/wp-content\/uploads\/3-planes-intersecting-infinite-solutions-copy.svg\" alt=\"\" width=\"170\"\r\n                    class=\"alignnone size-medium wp-image-27687\" \/><\/a>\r\n            <figcaption>3 planes &#8211; infinite solutions<\/figcaption>\r\n        <\/figure>\r\n        <div style=\"display: inline-block;\">&nbsp;&nbsp;<\/div>\r\n        <figure style=\"display: inline-block;\">\r\n            <a href=\"https:\/\/coertvonk.com\/wp-content\/uploads\/3-planes-intersecting-no-solutions-copy-1.svg\"><img\r\n                    src=\"https:\/\/coertvonk.com\/wp-content\/uploads\/3-planes-intersecting-no-solutions-copy-1.svg\" alt=\"\" width=\"170\"\r\n                    class=\"alignnone size-medium wp-image-27689\" \/><\/a>\r\n            <figcaption>3 planes &#8211; no solutions<\/figcaption>\r\n        <\/figure>\r\n    <\/div>\r\n<\/p>\r\n<p>\r\n    In matrix notation\r\n    $$\r\n        \\underbrace{\r\n            \\left[\\begin{array}{rrr}\r\n                1 &#038; 0 &#038; 1 \\\\\r\n                1 &#038; 1 &#038; 0 \\\\\r\n                1 &#038; 2 &#038; 3\r\n            \\end{array}\\right]\r\n        }_{A}\\;\r\n        \\underbrace{\r\n            \\left[\\begin{array}{ccc}\r\n                x \\\\ y \\\\ z\r\n            \\end{array}\\right]\r\n        }_{X} =\r\n        \\underbrace{\r\n            \\left[\\begin{array}{rrr}\r\n                1 \\\\ 2 \\\\ 3\r\n            \\end{array}\\right]\r\n        }_{B}\r\n        \\nonumber\r\n    $$\r\n<\/p>\r\n<p>\r\n    The solution to \\(AX=B\\) is given by (see <a href=\"#inverse\">Inverse matrix<\/a>)\r\n    $$\r\n        X = A^{-1}B\r\n        \\nonumber\r\n    $$\r\n<\/p>\r\n<p>\r\n    Recall\r\n    <blockquote>\r\n        $$\r\n            A^{-1}=\\frac{1}{\\det (A)}\\mathrm{adj}(A)\r\n            \\nonumber\r\n        $$\r\n    <\/blockquote>\r\n<\/p>\r\n<p>\r\n    This implies that matrix \\(A\\) is only <b>invertible<\/b> when\r\n    $$\r\n            \\shaded{\r\n            \\det (A)\\ne 0\r\n        }\r\n        \\nonumber\r\n    $$\r\n<\/p>\r\n<h3>Theory<\/h3>\r\n<h4>Homogeneous case<\/h4>\r\n<p>\r\n    Homogeneous means that equations are invariant under scaling. In matrix notation: \\(AX=0\\).\r\n<\/p>\r\n<p>\r\n    For example:\r\n    $$\r\n    \\left\\{\r\n        \\begin{align*}\r\n            x + z = 0 \\\\\r\n            x + y = 0 \\\\\r\n            x + 2y + 3z = 0\r\n        \\end{align*}\r\n    \\right.\r\n    $$\r\n<\/p>\r\n<p>\r\n    There is always the trivial solution: \\((0,0,0)\\).\r\n    <div class=\"align-center\">\r\n        <figure>\r\n            <a href=\"https:\/\/coertvonk.com\/wp-content\/uploads\/3-planes-intersecting-infinite-solutions-with-normal-vectors-copy.svg\"><img\r\n                    src=\"https:\/\/coertvonk.com\/wp-content\/uploads\/3-planes-intersecting-infinite-solutions-with-normal-vectors-copy.svg\"\r\n                    alt=\"\" width=\"220\" class=\"alignnone size-medium wp-image-27688\" \/><\/a>\r\n            <figcaption>3 planes &#8211; infinite solutions with normal vectors<\/figcaption>\r\n        <\/figure>\r\n    <\/div>\r\n<\/p>\r\n<p>\r\n    Depending on the \\(\\det(A)\\):\r\n    <ul>\r\n        <li>\r\n            If the \\(\\det (A)\\ne 0\\): \\(A\\) can be inverted. \\(AX=0 \\Leftrightarrow X=A^{-1}.0=0\\). No other\r\n            solutions.\r\n        <\/li>\r\n        <li>\r\n            If the \\(\\det (A)= 0\\): the <a href=\"\" linear-algebra-vectors-27609#determinant\">determinant<\/a> of\r\n            \\(\\vec{N_1},\\vec{N_2},\\vec{N_3}\\) equals \\(0\\). This implies that the plane&#8217;s normal vectors\r\n            \\(\\vec{N_1}\\), \\(\\vec{N_2}\\) and \\(\\vec{N_3}\\) are coplanar. A line through origin, perpendicular to\r\n            plane of \\(\\vec{N_1}, \\vec{N_2}, \\vec{N_3}\\) is parallel to all 3 planes and contained in them.\r\n            Therefore there are infinite many solutions. To find the solutions, one can take the cross-product of\r\n            two of the normals. It&#8217;s a nontrivial solution.\r\n        <\/li>\r\n    <\/ul>\r\n<\/p>\r\n<h3>General case<\/h3>\r\n<p>\r\n    The system\r\n    $$\r\n        AX=B\r\n        \\nonumber\r\n    $$\r\n<\/p>\r\n<p>\r\n    Depending on the \\(\\det(A)\\)\r\n    <ul>\r\n        <li>\r\n            if the \\(\\det {A}\\ne 0\\): there is an unique solution \\(X=A^{-1}B\\)\r\n        <\/li>\r\n        <li>\r\n            if the \\(\\det {A}=0\\): either no solution, or infinitely many solutions. If you would solve it by hand\r\n            and end up with \\(0=0\\), there are infinite solutions; if you end up with 1=2, there are no solutions.\r\n        <\/li>\r\n    <\/ul>\r\n<\/p>\r\n","protected":false},"excerpt":{"rendered":"Matrices can be used to express linear relations between variables. For example when we change coordinate systems.","protected":false},"author":41,"featured_media":27664,"comment_status":"open","ping_status":"closed","sticky":false,"template":"","format":"standard","meta":{"inline_featured_image":false,"_mi_skip_tracking":false},"categories":[407],"tags":[],"yoast_head":"<!-- This site is optimized with the Yoast SEO plugin v18.6 - https:\/\/yoast.com\/wordpress\/plugins\/seo\/ -->\n<title>Linear algebra matrices - Coert Vonk<\/title>\n<meta name=\"description\" content=\"My notes of linear algebra lecture &quot;Matrices&quot; by Denis Auroux. Course 18.02 Multivariable Calculus, OpenCourseWare, Fall 2007.\" \/>\n<meta name=\"robots\" content=\"index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1\" \/>\n<link rel=\"canonical\" href=\"https:\/\/coertvonk.com\/math\/multivariable-calculus\/linear-algebra\/matrices-27661\" \/>\n<meta property=\"og:locale\" content=\"en_US\" \/>\n<meta property=\"og:type\" content=\"article\" \/>\n<meta property=\"og:title\" content=\"Linear algebra matrices - Coert Vonk\" \/>\n<meta property=\"og:description\" content=\"My notes of linear algebra lecture &quot;Matrices&quot; by Denis Auroux. Course 18.02 Multivariable Calculus, OpenCourseWare, Fall 2007.\" \/>\n<meta property=\"og:url\" content=\"https:\/\/coertvonk.com\/math\/multivariable-calculus\/linear-algebra\/matrices-27661\" \/>\n<meta property=\"og:site_name\" content=\"Coert Vonk\" \/>\n<meta property=\"article:published_time\" content=\"2021-09-15T05:54:37+00:00\" \/>\n<meta property=\"article:modified_time\" content=\"2022-04-10T22:49:55+00:00\" \/>\n<meta name=\"twitter:card\" content=\"summary\" \/>\n<meta name=\"twitter:image\" content=\"https:\/\/coertvonk.com\/wp-content\/uploads\/matrix-multiplication-copy.svg\" \/>\n<meta name=\"twitter:label1\" content=\"Written by\" \/>\n\t<meta name=\"twitter:data1\" content=\"Coert Vonk\" \/>\n\t<meta name=\"twitter:label2\" content=\"Est. reading time\" \/>\n\t<meta name=\"twitter:data2\" content=\"8 minutes\" \/>\n<script type=\"application\/ld+json\" class=\"yoast-schema-graph\">{\"@context\":\"https:\/\/schema.org\",\"@graph\":[{\"@type\":\"WebSite\",\"@id\":\"http:\/\/coertvonk.com\/#website\",\"url\":\"http:\/\/coertvonk.com\/\",\"name\":\"Coert Vonk\",\"description\":\"Embedded Software Engineer\",\"publisher\":{\"@id\":\"http:\/\/coertvonk.com\/#\/schema\/person\/5eeda746b43b88312a0621fdc226c70e\"},\"potentialAction\":[{\"@type\":\"SearchAction\",\"target\":{\"@type\":\"EntryPoint\",\"urlTemplate\":\"http:\/\/coertvonk.com\/?s={search_term_string}\"},\"query-input\":\"required name=search_term_string\"}],\"inLanguage\":\"en-US\"},{\"@type\":\"ImageObject\",\"@id\":\"https:\/\/coertvonk.com\/math\/multivariable-calculus\/linear-algebra\/matrices-27661#primaryimage\",\"inLanguage\":\"en-US\",\"url\":\"https:\/\/coertvonk.com\/wp-content\/uploads\/matrix-multiplication-copy.svg\",\"contentUrl\":\"https:\/\/coertvonk.com\/wp-content\/uploads\/matrix-multiplication-copy.svg\"},{\"@type\":\"WebPage\",\"@id\":\"https:\/\/coertvonk.com\/math\/multivariable-calculus\/linear-algebra\/matrices-27661#webpage\",\"url\":\"https:\/\/coertvonk.com\/math\/multivariable-calculus\/linear-algebra\/matrices-27661\",\"name\":\"Linear algebra matrices - Coert Vonk\",\"isPartOf\":{\"@id\":\"http:\/\/coertvonk.com\/#website\"},\"primaryImageOfPage\":{\"@id\":\"https:\/\/coertvonk.com\/math\/multivariable-calculus\/linear-algebra\/matrices-27661#primaryimage\"},\"datePublished\":\"2021-09-15T05:54:37+00:00\",\"dateModified\":\"2022-04-10T22:49:55+00:00\",\"description\":\"My notes of linear algebra lecture \\\"Matrices\\\" by Denis Auroux. Course 18.02 Multivariable Calculus, OpenCourseWare, Fall 2007.\",\"breadcrumb\":{\"@id\":\"https:\/\/coertvonk.com\/math\/multivariable-calculus\/linear-algebra\/matrices-27661#breadcrumb\"},\"inLanguage\":\"en-US\",\"potentialAction\":[{\"@type\":\"ReadAction\",\"target\":[\"https:\/\/coertvonk.com\/math\/multivariable-calculus\/linear-algebra\/matrices-27661\"]}]},{\"@type\":\"BreadcrumbList\",\"@id\":\"https:\/\/coertvonk.com\/math\/multivariable-calculus\/linear-algebra\/matrices-27661#breadcrumb\",\"itemListElement\":[{\"@type\":\"ListItem\",\"position\":1,\"name\":\"Vonk Family\",\"item\":\"https:\/\/coertvonk.com\/\"},{\"@type\":\"ListItem\",\"position\":2,\"name\":\"Math\",\"item\":\"https:\/\/coertvonk.com\/category\/math\"},{\"@type\":\"ListItem\",\"position\":3,\"name\":\"Multivariable calculus\",\"item\":\"https:\/\/coertvonk.com\/category\/math\/multivariable-calculus\"},{\"@type\":\"ListItem\",\"position\":4,\"name\":\"Linear Algebra\",\"item\":\"https:\/\/coertvonk.com\/category\/math\/multivariable-calculus\/linear-algebra\"},{\"@type\":\"ListItem\",\"position\":5,\"name\":\"Matrices\"}]},{\"@type\":\"Article\",\"@id\":\"https:\/\/coertvonk.com\/math\/multivariable-calculus\/linear-algebra\/matrices-27661#article\",\"isPartOf\":{\"@id\":\"https:\/\/coertvonk.com\/math\/multivariable-calculus\/linear-algebra\/matrices-27661#webpage\"},\"author\":{\"@id\":\"http:\/\/coertvonk.com\/#\/schema\/person\/5eeda746b43b88312a0621fdc226c70e\"},\"headline\":\"Matrices\",\"datePublished\":\"2021-09-15T05:54:37+00:00\",\"dateModified\":\"2022-04-10T22:49:55+00:00\",\"mainEntityOfPage\":{\"@id\":\"https:\/\/coertvonk.com\/math\/multivariable-calculus\/linear-algebra\/matrices-27661#webpage\"},\"wordCount\":1578,\"commentCount\":0,\"publisher\":{\"@id\":\"http:\/\/coertvonk.com\/#\/schema\/person\/5eeda746b43b88312a0621fdc226c70e\"},\"image\":{\"@id\":\"https:\/\/coertvonk.com\/math\/multivariable-calculus\/linear-algebra\/matrices-27661#primaryimage\"},\"thumbnailUrl\":\"https:\/\/coertvonk.com\/wp-content\/uploads\/matrix-multiplication-copy.svg\",\"articleSection\":[\"Linear Algebra\"],\"inLanguage\":\"en-US\"},{\"@type\":[\"Person\",\"Organization\"],\"@id\":\"http:\/\/coertvonk.com\/#\/schema\/person\/5eeda746b43b88312a0621fdc226c70e\",\"name\":\"Coert Vonk\",\"image\":{\"@type\":\"ImageObject\",\"@id\":\"http:\/\/coertvonk.com\/#personlogo\",\"inLanguage\":\"en-US\",\"url\":\"http:\/\/1.gravatar.com\/avatar\/193315b96c6661985694e2ecd91f2996?s=96&d=mm&r=g\",\"contentUrl\":\"http:\/\/1.gravatar.com\/avatar\/193315b96c6661985694e2ecd91f2996?s=96&d=mm&r=g\",\"caption\":\"Coert Vonk\"},\"logo\":{\"@id\":\"http:\/\/coertvonk.com\/#personlogo\"},\"description\":\"Passionately curious and stubbornly persistent. Enjoys to inspire and consult with others to exchange the poetry of logical ideas.\",\"sameAs\":[\"https:\/\/coertvonk.com\"],\"url\":\"http:\/\/coertvonk.com\/author\/cvonk\"}]}<\/script>\n<!-- \/ Yoast SEO plugin. -->","yoast_head_json":{"title":"Linear algebra matrices - Coert Vonk","description":"My notes of linear algebra lecture \"Matrices\" by Denis Auroux. Course 18.02 Multivariable Calculus, OpenCourseWare, Fall 2007.","robots":{"index":"index","follow":"follow","max-snippet":"max-snippet:-1","max-image-preview":"max-image-preview:large","max-video-preview":"max-video-preview:-1"},"canonical":"https:\/\/coertvonk.com\/math\/multivariable-calculus\/linear-algebra\/matrices-27661","og_locale":"en_US","og_type":"article","og_title":"Linear algebra matrices - Coert Vonk","og_description":"My notes of linear algebra lecture \"Matrices\" by Denis Auroux. Course 18.02 Multivariable Calculus, OpenCourseWare, Fall 2007.","og_url":"https:\/\/coertvonk.com\/math\/multivariable-calculus\/linear-algebra\/matrices-27661","og_site_name":"Coert Vonk","article_published_time":"2021-09-15T05:54:37+00:00","article_modified_time":"2022-04-10T22:49:55+00:00","twitter_card":"summary","twitter_image":"https:\/\/coertvonk.com\/wp-content\/uploads\/matrix-multiplication-copy.svg","twitter_misc":{"Written by":"Coert Vonk","Est. reading time":"8 minutes"},"schema":{"@context":"https:\/\/schema.org","@graph":[{"@type":"WebSite","@id":"http:\/\/coertvonk.com\/#website","url":"http:\/\/coertvonk.com\/","name":"Coert Vonk","description":"Embedded Software Engineer","publisher":{"@id":"http:\/\/coertvonk.com\/#\/schema\/person\/5eeda746b43b88312a0621fdc226c70e"},"potentialAction":[{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"http:\/\/coertvonk.com\/?s={search_term_string}"},"query-input":"required name=search_term_string"}],"inLanguage":"en-US"},{"@type":"ImageObject","@id":"https:\/\/coertvonk.com\/math\/multivariable-calculus\/linear-algebra\/matrices-27661#primaryimage","inLanguage":"en-US","url":"https:\/\/coertvonk.com\/wp-content\/uploads\/matrix-multiplication-copy.svg","contentUrl":"https:\/\/coertvonk.com\/wp-content\/uploads\/matrix-multiplication-copy.svg"},{"@type":"WebPage","@id":"https:\/\/coertvonk.com\/math\/multivariable-calculus\/linear-algebra\/matrices-27661#webpage","url":"https:\/\/coertvonk.com\/math\/multivariable-calculus\/linear-algebra\/matrices-27661","name":"Linear algebra matrices - Coert Vonk","isPartOf":{"@id":"http:\/\/coertvonk.com\/#website"},"primaryImageOfPage":{"@id":"https:\/\/coertvonk.com\/math\/multivariable-calculus\/linear-algebra\/matrices-27661#primaryimage"},"datePublished":"2021-09-15T05:54:37+00:00","dateModified":"2022-04-10T22:49:55+00:00","description":"My notes of linear algebra lecture \"Matrices\" by Denis Auroux. Course 18.02 Multivariable Calculus, OpenCourseWare, Fall 2007.","breadcrumb":{"@id":"https:\/\/coertvonk.com\/math\/multivariable-calculus\/linear-algebra\/matrices-27661#breadcrumb"},"inLanguage":"en-US","potentialAction":[{"@type":"ReadAction","target":["https:\/\/coertvonk.com\/math\/multivariable-calculus\/linear-algebra\/matrices-27661"]}]},{"@type":"BreadcrumbList","@id":"https:\/\/coertvonk.com\/math\/multivariable-calculus\/linear-algebra\/matrices-27661#breadcrumb","itemListElement":[{"@type":"ListItem","position":1,"name":"Vonk Family","item":"https:\/\/coertvonk.com\/"},{"@type":"ListItem","position":2,"name":"Math","item":"https:\/\/coertvonk.com\/category\/math"},{"@type":"ListItem","position":3,"name":"Multivariable calculus","item":"https:\/\/coertvonk.com\/category\/math\/multivariable-calculus"},{"@type":"ListItem","position":4,"name":"Linear Algebra","item":"https:\/\/coertvonk.com\/category\/math\/multivariable-calculus\/linear-algebra"},{"@type":"ListItem","position":5,"name":"Matrices"}]},{"@type":"Article","@id":"https:\/\/coertvonk.com\/math\/multivariable-calculus\/linear-algebra\/matrices-27661#article","isPartOf":{"@id":"https:\/\/coertvonk.com\/math\/multivariable-calculus\/linear-algebra\/matrices-27661#webpage"},"author":{"@id":"http:\/\/coertvonk.com\/#\/schema\/person\/5eeda746b43b88312a0621fdc226c70e"},"headline":"Matrices","datePublished":"2021-09-15T05:54:37+00:00","dateModified":"2022-04-10T22:49:55+00:00","mainEntityOfPage":{"@id":"https:\/\/coertvonk.com\/math\/multivariable-calculus\/linear-algebra\/matrices-27661#webpage"},"wordCount":1578,"commentCount":0,"publisher":{"@id":"http:\/\/coertvonk.com\/#\/schema\/person\/5eeda746b43b88312a0621fdc226c70e"},"image":{"@id":"https:\/\/coertvonk.com\/math\/multivariable-calculus\/linear-algebra\/matrices-27661#primaryimage"},"thumbnailUrl":"https:\/\/coertvonk.com\/wp-content\/uploads\/matrix-multiplication-copy.svg","articleSection":["Linear Algebra"],"inLanguage":"en-US"},{"@type":["Person","Organization"],"@id":"http:\/\/coertvonk.com\/#\/schema\/person\/5eeda746b43b88312a0621fdc226c70e","name":"Coert Vonk","image":{"@type":"ImageObject","@id":"http:\/\/coertvonk.com\/#personlogo","inLanguage":"en-US","url":"http:\/\/1.gravatar.com\/avatar\/193315b96c6661985694e2ecd91f2996?s=96&d=mm&r=g","contentUrl":"http:\/\/1.gravatar.com\/avatar\/193315b96c6661985694e2ecd91f2996?s=96&d=mm&r=g","caption":"Coert Vonk"},"logo":{"@id":"http:\/\/coertvonk.com\/#personlogo"},"description":"Passionately curious and stubbornly persistent. Enjoys to inspire and consult with others to exchange the poetry of logical ideas.","sameAs":["https:\/\/coertvonk.com"],"url":"http:\/\/coertvonk.com\/author\/cvonk"}]}},"_links":{"self":[{"href":"http:\/\/coertvonk.com\/wp-json\/wp\/v2\/posts\/27661"}],"collection":[{"href":"http:\/\/coertvonk.com\/wp-json\/wp\/v2\/posts"}],"about":[{"href":"http:\/\/coertvonk.com\/wp-json\/wp\/v2\/types\/post"}],"author":[{"embeddable":true,"href":"http:\/\/coertvonk.com\/wp-json\/wp\/v2\/users\/41"}],"replies":[{"embeddable":true,"href":"http:\/\/coertvonk.com\/wp-json\/wp\/v2\/comments?post=27661"}],"version-history":[{"count":5,"href":"http:\/\/coertvonk.com\/wp-json\/wp\/v2\/posts\/27661\/revisions"}],"predecessor-version":[{"id":32222,"href":"http:\/\/coertvonk.com\/wp-json\/wp\/v2\/posts\/27661\/revisions\/32222"}],"wp:featuredmedia":[{"embeddable":true,"href":"http:\/\/coertvonk.com\/wp-json\/wp\/v2\/media\/27664"}],"wp:attachment":[{"href":"http:\/\/coertvonk.com\/wp-json\/wp\/v2\/media?parent=27661"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"http:\/\/coertvonk.com\/wp-json\/wp\/v2\/categories?post=27661"},{"taxonomy":"post_tag","embeddable":true,"href":"http:\/\/coertvonk.com\/wp-json\/wp\/v2\/tags?post=27661"}],"curies":[{"name":"wp","href":"https:\/\/api.w.org\/{rel}","templated":true}]}}